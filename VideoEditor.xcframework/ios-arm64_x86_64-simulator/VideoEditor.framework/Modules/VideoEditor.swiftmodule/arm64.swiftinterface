// swift-interface-format-version: 1.0
// swift-compiler-version: Apple Swift version 5.5 (swiftlang-1300.0.31.1 clang-1300.0.29.1)
// swift-module-flags: -target arm64-apple-ios11.0-simulator -enable-objc-interop -enable-library-evolution -swift-version 5 -enforce-exclusivity=checked -Onone -module-name VideoEditor
import AVFoundation
import AVKit
import BanubaLicenseServicingSDK
import BanubaUtilities
import CoreGraphics
import CoreMedia
import CoreVideo
import Foundation
import GLKit
import OpenGLES
import QuartzCore
import Swift
import UIKit
@_exported import VideoEditor
import _Concurrency
public protocol VideoEditorImageAssetProtocol : AnyObject {
  var duration: Foundation.TimeInterval { get }
  var image: CoreGraphics.CGImage? { get }
  var shouldUseImageEffect: Swift.Bool { get }
  func getOrPreloadImage() -> CoreGraphics.CGImage?
  func unloadImage()
}
@_hasMissingDesignatedInitializers public class AudioMixer {
  public struct VolumeDefaults {
    public static var defaultVolume: Swift.Float
    public static var muteVolume: Swift.Float
  }
  public var audioMix: AVFoundation.AVAudioMix {
    get
  }
  public func resetTrackVolumeToDefault(trackId: CoreMedia.CMPersistentTrackID)
  public func setVolume(_ volume: Swift.Float, forTrackId trackId: CoreMedia.CMPersistentTrackID)
  public func volume(forTrackId trackId: CoreMedia.CMPersistentTrackID) -> Swift.Float
  public func isVolumeDefault(forTrackId trackId: CoreMedia.CMPersistentTrackID) -> Swift.Bool
  @objc deinit
}
public protocol CompositionRenderering : AnyObject {
  init()
  func render(in pixelBuffer: CoreVideo.CVPixelBuffer, allSources: [CoreVideo.CVPixelBuffer], sampleTime: CoreMedia.CMTime, effect: VideoEditor.EditorCompositionEffectProtocol)
}
@_hasMissingDesignatedInitializers public class PlayersBundle {
  weak public var playerDelegate: BanubaUtilities.PlayerDelegate?
  public var isMuted: Swift.Bool {
    get
    set(value)
  }
  @objc deinit
}
extension VideoEditor.PlayersBundle : BanubaUtilities.Playable {
  public var currentTime: Foundation.TimeInterval {
    get
  }
  public var videoDuration: Swift.Double {
    get
  }
  public var currentTimeInCMTime: CoreMedia.CMTime {
    get
  }
  public var videoDurationCMTime: CoreMedia.CMTime {
    get
  }
  public var isPlaying: Swift.Bool {
    get
  }
  public var playerItem: AVFoundation.AVPlayerItem? {
    get
  }
  public var audioMix: AVFoundation.AVAudioMix? {
    get
    set(newValue)
  }
  public var avPlayer: AVFoundation.AVPlayer {
    get
  }
  public var startTimePlay: CoreMedia.CMTime {
    get
  }
  public var endTimePlay: CoreMedia.CMTime {
    get
  }
  public func startPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool)
  public func startPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool, start: CoreMedia.CMTime, end: CoreMedia.CMTime)
  public func pausePlay()
  public func stopPlay()
  public func resumePlay()
  public func previewLayer() -> AVFoundation.AVPlayerLayer
  public func smoothlySeek(to time: CoreMedia.CMTime)
  public func seek(to time: CoreMedia.CMTime)
  public func startStopPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool)
  public func reloadPreview()
  public func reloadPreview(shouldAutoStart: Swift.Bool)
}
extension VideoEditor.PlayersBundle : BanubaUtilities.PlayerDelegate {
  public func playerDidEndPlaying(_ preview: BanubaUtilities.Playable)
  public func playerPlaysFrame(_ preview: BanubaUtilities.Playable, atTime time: CoreMedia.CMTime)
}
public enum EditorEffectType : Swift.Int {
  case gif
  case text
  case time
  case color
  case visual
  case mask
  case transform
  public init?(rawValue: Swift.Int)
  public typealias RawValue = Swift.Int
  public var rawValue: Swift.Int {
    get
  }
}
public protocol VideoEditorTrackServicing {
  func hasAudioTrack() -> Swift.Bool
  func audioTrackVolume() -> Swift.Float
  func isAudioTrackVolumeChanged() -> Swift.Bool
  func setAudioTrackVolume(_ volume: Swift.Float)
  func setAudioTrackVolume(_ volume: Swift.Float, to player: BanubaUtilities.Playable?)
}
public protocol WatermarkApplicatorServicing : AnyObject {
  func adjustWatermarkEffect(configuration: VideoEditor.WatermarkConfiguration, videoSize: CoreGraphics.CGSize) -> VideoEditor.VideoEditorFilterModel
}
public protocol ImageSlideshow {
  func exportSlideshowImages(_ images: [VideoEditor.VideoEditorImageAssetProtocol], to fileUrl: Foundation.URL?, videoResolution: BanubaUtilities.VideoResolution, completion: ((Swift.Bool, Foundation.URL, Swift.Error?) -> Swift.Void)?)
}
extension VideoEditor.ImageSlideshow {
  public func exportSlideshowImages(_ images: [VideoEditor.VideoEditorImageAssetProtocol], to fileUrl: Foundation.URL? = nil, videoResolution: BanubaUtilities.VideoResolution, completion: ((Swift.Bool, Foundation.URL, Swift.Error?) -> Swift.Void)?)
}
public protocol VideoEditorServicing : VideoEditor.AppliedEffect, VideoEditor.ImageSlideshow, VideoEditor.VideoEditorTrackServicing {
  var asset: AVFoundation.AVAsset? { get }
  var videoAsset: VideoEditor.VideoEditorAsset? { get set }
  var exportFrameDuration: CoreMedia.CMTime { get set }
  var videoSize: CoreGraphics.CGSize { get set }
  func exportVideo(to fileURL: Foundation.URL, using exportVideoInfo: VideoEditor.ExportVideoInfo, watermarkFilterModel: VideoEditor.VideoEditorFilterModel?, completion: ((_ isSuccess: Swift.Bool, _ error: Swift.Error?) -> Swift.Void)?)
  func exportAudio(to fileURL: Foundation.URL, completion: ((_ isSuccess: Swift.Bool, _ error: Swift.Error?) -> Swift.Void)?)
  func mergeVideoWithAudio(videoUrl: Foundation.URL, audioUrl: Foundation.URL, videoSize: CoreGraphics.CGSize, audioStartTime: Foundation.TimeInterval, success: @escaping ((Foundation.URL) -> Swift.Void), failure: @escaping ((Swift.Error?) -> Swift.Void))
  func getEditorEffects(type: VideoEditor.EditorEffectType) -> [VideoEditor.VideoEditorFilterModel]
  func setCurrentAsset(_ asset: VideoEditor.VideoEditorAsset?)
  func getPlayer(delegate: BanubaUtilities.PlayerDelegate?) -> BanubaUtilities.Playable
  func setEditorEffects(_ effects: [VideoEditor.VideoEditorFilterModel])
  func getImageGenerator() -> AVFoundation.AVAssetImageGenerator?
  func videoPartsCount() -> Swift.Int
  static func getPlayer(asset: AVFoundation.AVAsset, delegate: BanubaUtilities.PlayerDelegate?) -> BanubaUtilities.Playable
  static func getPlayer(asset: AVFoundation.AVAsset, delegate: BanubaUtilities.PlayerDelegate?, instructions: [AVFoundation.AVVideoCompositionInstructionProtocol]?) -> BanubaUtilities.Playable
  init(token: Swift.String, watermarkApplicator: VideoEditor.WatermarkApplicatorServicing)
}
public class VideoEditorService {
  public var videoAsset: VideoEditor.VideoEditorAsset? {
    get
    set(value)
  }
  public var asset: AVFoundation.AVAsset? {
    get
  }
  public var videoSize: CoreGraphics.CGSize
  public var exportFrameDuration: CoreMedia.CMTime
  public var audioMixer: VideoEditor.AudioMixer?
  required public init(token: Swift.String, watermarkApplicator: VideoEditor.WatermarkApplicatorServicing)
  @objc deinit
}
extension VideoEditor.VideoEditorService : VideoEditor.AppliedEffect {
  public func applyFilter(effectModel: VideoEditor.VideoEditorFilterModel, start: CoreMedia.CMTime, end: CoreMedia.CMTime, removeSameType: Swift.Bool)
  public func getSpeed(at time: CoreMedia.CMTime) -> Swift.Float
  public func undoLast(type: VideoEditor.EditorEffectType) -> VideoEditor.EditorCompositionEffectProtocol?
  public func undoAll(type: VideoEditor.EditorEffectType)
  public func startCurrentFilter(effectModel: VideoEditor.VideoEditorFilterModel, at: CoreMedia.CMTime)
  public func endCurrentFilter(at: CoreMedia.CMTime)
  public func getCurrentAppliedEffects(type: VideoEditor.EditorEffectType) -> [VideoEditor.EditorCompositionEffectProtocol]
  public func getCurrentAppliedEffects() -> [VideoEditor.EditorCompositionEffectProtocol]
  public func storeStack()
  public func restoreStack()
  public func hasChangesInAppliedEffects() -> Swift.Bool
}
extension VideoEditor.VideoEditorService : VideoEditor.VideoEditorServicing {
  public static func getPlayer(asset: AVFoundation.AVAsset, delegate: BanubaUtilities.PlayerDelegate?) -> BanubaUtilities.Playable
  public static func getPlayer(asset: AVFoundation.AVAsset, delegate: BanubaUtilities.PlayerDelegate?, instructions: [AVFoundation.AVVideoCompositionInstructionProtocol]?) -> BanubaUtilities.Playable
  public func getImageGenerator() -> AVFoundation.AVAssetImageGenerator?
  public func exportVideo(to fileURL: Foundation.URL, using exportVideoInfo: VideoEditor.ExportVideoInfo, watermarkFilterModel: VideoEditor.VideoEditorFilterModel?, completion: ((_ isSuccess: Swift.Bool, _ error: Swift.Error?) -> Swift.Void)?)
  public func exportCleanVideo(to file: Foundation.URL, mediaInfo: VideoEditor.ExportVideoInfo, completion: ((_ isSuccess: Swift.Bool, _ error: Swift.Error?) -> Swift.Void)?)
  public func exportAudio(to fileURL: Foundation.URL, completion: ((_ isSuccess: Swift.Bool, _ error: Swift.Error?) -> Swift.Void)?)
  public func mergeVideoWithAudio(videoUrl: Foundation.URL, audioUrl: Foundation.URL, videoSize: CoreGraphics.CGSize, audioStartTime: Foundation.TimeInterval, success: @escaping ((Foundation.URL) -> Swift.Void), failure: @escaping ((Swift.Error?) -> Swift.Void))
  public func getEditorEffects(type: VideoEditor.EditorEffectType) -> [VideoEditor.VideoEditorFilterModel]
  public func setCurrentAsset(_ asset: VideoEditor.VideoEditorAsset?)
  public func getPlayer(delegate: BanubaUtilities.PlayerDelegate?) -> BanubaUtilities.Playable
  public func setEditorEffects(_ effects: [VideoEditor.VideoEditorFilterModel])
  public func videoPartsCount() -> Swift.Int
}
extension VideoEditor.VideoEditorService : VideoEditor.VideoEditorTrackServicing {
  public func audioTrackVolume() -> Swift.Float
  public func isAudioTrackVolumeChanged() -> Swift.Bool
  public func setAudioTrackVolume(_ volume: Swift.Float)
  public func setAudioTrackVolume(_ volume: Swift.Float, to player: BanubaUtilities.Playable?)
  public func hasAudioTrack() -> Swift.Bool
}
extension VideoEditor.VideoEditorService : VideoEditor.ImageSlideshow {
  public func exportSlideshowImages(_ images: [VideoEditor.VideoEditorImageAssetProtocol], to fileUrl: Foundation.URL? = nil, videoResolution: BanubaUtilities.VideoResolution, completion: ((Swift.Bool, Foundation.URL, Swift.Error?) -> Swift.Void)?)
}
public class VideoTrimData {
  public var start: CoreMedia.CMTime {
    get
  }
  public var end: CoreMedia.CMTime {
    get
  }
  public var duration: CoreMedia.CMTime {
    get
  }
  public init(start: CoreMedia.CMTime, end: CoreMedia.CMTime)
  @objc deinit
}
public class MusicPlayer : BanubaUtilities.Playable {
  public var avPlayer: AVFoundation.AVPlayer {
    get
  }
  public var playerItem: AVFoundation.AVPlayerItem? {
    get
  }
  public var isMuted: Swift.Bool {
    get
    set(value)
  }
  weak public var playerDelegate: BanubaUtilities.PlayerDelegate?
  public var isPlaying: Swift.Bool
  public var startTimePlay: CoreMedia.CMTime {
    get
  }
  public var endTimePlay: CoreMedia.CMTime {
    get
  }
  public init(item: AVFoundation.AVPlayerItem?)
  @objc deinit
}
extension VideoEditor.MusicPlayer {
  public var videoDurationCMTime: CoreMedia.CMTime {
    get
  }
  public var videoDuration: Swift.Double {
    get
  }
  public var currentTimeInCMTime: CoreMedia.CMTime {
    get
  }
  public var currentTime: Foundation.TimeInterval {
    get
  }
  public var audioMix: AVFoundation.AVAudioMix? {
    get
    set(newValue)
  }
  public func seek(to time: CoreMedia.CMTime)
  public func reloadPreview()
  public func reloadPreview(shouldAutoStart: Swift.Bool)
  public func startStopPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool)
  public func stopPlay()
  public func smoothlySeek(to time: CoreMedia.CMTime)
  public func previewLayer() -> AVFoundation.AVPlayerLayer
  public func resumePlay()
  public func pausePlay()
  public func startPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool)
  public func startPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool, start: CoreMedia.CMTime, end: CoreMedia.CMTime)
}
public protocol ExportScalable {
  func exportScaled(outputUrl: Foundation.URL, quality: Swift.String, trimData: VideoEditor.VideoTrimData?, completion: ((Swift.Error?) -> Swift.Void)?)
}
public protocol AssetEditable {
  func addTracks(_ tracks: [VideoEditor.VideoEditorAssetTrackInfo])
  func removeTrack(at index: Swift.Int)
  func removeTrack(_ track: VideoEditor.VideoEditorAssetTrackInfo)
  func moveTrack(fromIndex: Swift.Int, toIndex: Swift.Int)
  func reorderTracks(withOrderedUrls orderedUrls: [Foundation.URL])
}
public class VideoEditorAsset {
  public var composition: AVFoundation.AVMutableComposition!
  public var instructions: [AVFoundation.AVVideoCompositionInstructionProtocol]? {
    get
  }
  public var errors: [Swift.Error] {
    get
  }
  public var tracksInfo: [VideoEditor.VideoEditorAssetTrackInfo] {
    get
  }
  final public let videoResolutionConfiguration: BanubaUtilities.VideoResolutionConfiguration
  public var videoResolutionCurrentSize: CoreGraphics.CGSize?
  public var fillAspectRatioRange: Swift.ClosedRange<CoreGraphics.CGFloat>
  public init(tracks: [VideoEditor.VideoEditorAssetTrackInfo], isDebugModeOn: Swift.Bool = false, fillAspectRatioRange: Swift.ClosedRange<CoreGraphics.CGFloat> = CGFloat(0)...CGFloat(0), videoResolutionConfiguration: BanubaUtilities.VideoResolutionConfiguration)
  public convenience init(sequence: VideoEditor.VideoSequence, isGalleryAssets: Swift.Bool, isSlideShow: Swift.Bool, isDebugModeOn: Swift.Bool = false, fillAspectRatioRange: Swift.ClosedRange<CoreGraphics.CGFloat> = CGFloat(0)...CGFloat(0), videoResolutionConfiguration: BanubaUtilities.VideoResolutionConfiguration)
  public func reloadComposition()
  public func loadNonExistingThumbnails(completion: (() -> ())?)
  public func getPartIndex(at time: CoreMedia.CMTime) -> Swift.Int?
  @objc deinit
}
extension VideoEditor.VideoEditorAsset {
  public func changeMusicTrackPosition(_ musicTrack: VideoEditor.MediaTrack) -> Swift.Bool
  @discardableResult
  public func addMusicTrack(_ musicTrack: VideoEditor.MediaTrack) -> (compositionTrack: AVFoundation.AVMutableCompositionTrack, assetTrack: AVFoundation.AVAssetTrack)?
  @discardableResult
  public func removeMusic(trackId: CoreMedia.CMPersistentTrackID) -> Swift.Bool
}
extension VideoEditor.VideoEditorAsset : VideoEditor.ExportScalable {
  public func exportScaled(outputUrl: Foundation.URL, quality: Swift.String, trimData: VideoEditor.VideoTrimData?, completion: ((Swift.Error?) -> Swift.Void)?)
}
extension VideoEditor.VideoEditorAsset : VideoEditor.AssetEditable {
  public func addTracks(_ tracks: [VideoEditor.VideoEditorAssetTrackInfo])
  public func removeTrack(at index: Swift.Int)
  public func removeTrack(_ track: VideoEditor.VideoEditorAssetTrackInfo)
  public func moveTrack(fromIndex: Swift.Int, toIndex: Swift.Int)
  public func reorderTracks(withOrderedUrls orderedUrls: [Foundation.URL])
}
@_hasMissingDesignatedInitializers public class VideoAspectRatioCalculator {
  public static func calculateVideoAspectRatio(withVideoSize videoSize: CoreGraphics.CGSize) -> Swift.Double
  public static func adjustVideoSize(_ videoSize: CoreGraphics.CGSize, withAspectRatio aspectRatio: Swift.Double) -> CoreGraphics.CGSize
  @objc deinit
}
public class VideoTextureCache {
  public init(with context: OpenGLES.EAGLContext)
  public func flush()
  public func rgbaTextureForPixelBuffer(_ pixelBuffer: CoreVideo.CVPixelBuffer) -> CoreVideo.CVOpenGLESTexture?
  @objc deinit
}
public enum ExportQuality {
  case videoConfiguration(VideoEditor.ExportVideoInfo)
  case auto
}
public struct GifSettings {
  public var duration: Foundation.TimeInterval
  public init(duration: Foundation.TimeInterval)
}
public struct ExportConfiguration {
  public let videoConfigurations: [VideoEditor.ExportVideoConfiguration]
  public let isCoverEnabled: Swift.Bool
  public var gifSettings: VideoEditor.GifSettings?
  public init(videoConfigurations: [VideoEditor.ExportVideoConfiguration], isCoverEnabled: Swift.Bool, gifSettings: VideoEditor.GifSettings?)
}
public struct ExportVideoConfiguration {
  public let fileURL: Foundation.URL
  public let quality: VideoEditor.ExportQuality
  public let watermarkConfiguration: VideoEditor.WatermarkConfiguration?
  public let useHEVCCodecIfPossible: Swift.Bool
  public init(fileURL: Foundation.URL, quality: VideoEditor.ExportQuality, useHEVCCodecIfPossible: Swift.Bool, watermarkConfiguration: VideoEditor.WatermarkConfiguration?)
}
public enum ContentLocationType {
  case remote
  case local
  public static func == (a: VideoEditor.ContentLocationType, b: VideoEditor.ContentLocationType) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
public class VideoEditorFilterModel {
  public var id: Swift.UInt {
    get
  }
  public var tokenId: Swift.String {
    get
  }
  final public let filterType: VideoEditor.EditorEffectType
  final public let name: Swift.String
  final public let path: Swift.String
  final public let contentLocationType: VideoEditor.ContentLocationType
  public var preview: Foundation.URL?
  public convenience init(name: Swift.String, type: VideoEditor.EditorEffectType, contentLocationType: VideoEditor.ContentLocationType = .local, renderer: VideoEditor.CompositionRenderering.Type?, path: Swift.String = "", id: Swift.UInt, tokenId: Swift.String, rendererInstance: VideoEditor.CompositionRenderering?, preview: Foundation.URL? = nil)
  public init(name: Swift.String, type: VideoEditor.EditorEffectType, contentLocationType: VideoEditor.ContentLocationType = .local, renderer: VideoEditor.CompositionRenderering.Type?, path: Swift.String = "", speed: VideoEditor.EffectSpeed = .normal, id: Swift.UInt, tokenId: Swift.String, rendererInstance: VideoEditor.CompositionRenderering?, preview: Foundation.URL? = nil)
  @objc deinit
}
public class SimpleTextGLRenderer {
  required public init()
  @objc deinit
  public func renderToCurrentFramebuffer(screenSymbolsWidth: Swift.UInt32, screenSymbolsHeight: Swift.UInt32, text: [OpenGLES.GLint])
}
public class VideoSequenceItem {
  final public let url: Foundation.URL
  final public let duration: Foundation.TimeInterval
  final public let isGalleryAsset: Swift.Bool
  public var rotation: VideoEditor.AssetRotation
  final public let preview: UIKit.UIImage?
  public var speed: Swift.Double {
    get
  }
  public init(assetUrl url: Foundation.URL, isGalleryAsset: Swift.Bool, rotation: VideoEditor.AssetRotation, preview: UIKit.UIImage?)
  @objc deinit
}
@objc public class VideoSequence : ObjectiveC.NSObject {
  final public let folderURL: Foundation.URL
  public var modificationDate: Foundation.Date
  public var preview: UIKit.UIImage?
  public var videos: [VideoEditor.VideoSequenceItem]
  public var sequenceId: Swift.String {
    get
  }
  public var durations: [Foundation.TimeInterval] {
    get
  }
  public var initialDurations: [Foundation.TimeInterval] {
    get
  }
  public var isGallerySequence: Swift.Bool {
    get
  }
  required public init(folderURL: Foundation.URL)
  public static func generateName() -> Swift.String
  @discardableResult
  public func addVideo(at url: Foundation.URL, speed: Swift.Double = 1.0, isGalleryAsset: Swift.Bool = false, isOriginalVideo: Swift.Bool = false, rotation: VideoEditor.AssetRotation = .none, preview: UIKit.UIImage? = nil, shouldMoveFile: Swift.Bool = true, shouldUseUniqName: Swift.Bool = true) -> VideoEditor.VideoSequenceItem?
  @discardableResult
  public func removeVideo(_ video: VideoEditor.VideoSequenceItem) -> Swift.Bool
  public func totalDuration(isSpeedCountingEnabled: Swift.Bool = true) -> Foundation.TimeInterval
  @discardableResult
  public func removeLastVideo() -> VideoEditor.VideoSequenceItem?
  public func remove()
  public func reorderVideos(withOrderedVideoUrls orderedUrls: [Foundation.URL])
  public func replaceVideos(withNewVideos videos: [Foundation.URL], isGalleryItems: Swift.Bool)
  public func hasReplacedVideos() -> Swift.Bool
  public func restoreOriginalVideos()
  @objc deinit
}
extension VideoEditor.VideoSequence {
  public func didUpdateVideo(_ video: VideoEditor.VideoSequenceItem)
}
@objc public class VoiceTrackItem : ObjectiveC.NSObject {
  final public let url: Foundation.URL
  final public let timeRange: CoreMedia.CMTimeRange
  public init(url: Foundation.URL, timeRange: CoreMedia.CMTimeRange)
  @objc deinit
}
public class ExportVideoInfo {
  public enum Resolution : Swift.String {
    case ld360
    case md480
    case md540
    case hd720
    case fullHd1080
    public var size: CoreGraphics.CGSize {
      get
    }
    public init?(rawValue: Swift.String)
    public typealias RawValue = Swift.String
    public var rawValue: Swift.String {
      get
    }
  }
  final public let resolution: VideoEditor.ExportVideoInfo.Resolution
  public init(resolution: VideoEditor.ExportVideoInfo.Resolution, useHEVCCodecIfPossible: Swift.Bool, frameRate: Swift.Int = 30, scalingMode: Swift.String = AVVideoScalingModeResize)
  @objc deinit
}
public struct ExportVideoInfoFactory {
  public static func assetExportSettings(resolution: BanubaUtilities.VideoResolution, useHEVCCodecIfPossible: Swift.Bool, frameRate: Swift.Int = 30, scalingMode: Swift.String = AVVideoScalingModeResize) -> VideoEditor.ExportVideoInfo
}
public struct VideoSequenceNameDuplacatesFinder {
  public let sequenceName: Swift.String
  public init(sequenceName: Swift.String)
  public func findDuplicates(inSequenceNames sequenceNames: [Swift.String]) -> [Swift.String]
}
@_hasMissingDesignatedInitializers public class EditorPlayer {
  public var avPlayer: AVFoundation.AVPlayer {
    get
  }
  public var playerItem: AVFoundation.AVPlayerItem? {
    get
  }
  public var isMuted: Swift.Bool {
    get
    set(value)
  }
  weak public var playerDelegate: BanubaUtilities.PlayerDelegate?
  public var isPlaying: Swift.Bool
  public var startTimePlay: CoreMedia.CMTime {
    get
  }
  public var endTimePlay: CoreMedia.CMTime {
    get
  }
  @objc deinit
}
extension VideoEditor.EditorPlayer : BanubaUtilities.Playable {
  public var videoDurationCMTime: CoreMedia.CMTime {
    get
  }
  public var videoDuration: Swift.Double {
    get
  }
  public var currentTimeInCMTime: CoreMedia.CMTime {
    get
  }
  public var currentTime: Foundation.TimeInterval {
    get
  }
  public var audioMix: AVFoundation.AVAudioMix? {
    get
    set(newValue)
  }
  public func seek(to time: CoreMedia.CMTime)
  public func reloadPreview()
  public func reloadPreview(shouldAutoStart: Swift.Bool)
  public func startStopPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool)
  public func stopPlay()
  public func smoothlySeek(to time: CoreMedia.CMTime)
  public func previewLayer() -> AVFoundation.AVPlayerLayer
  public func resumePlay()
  public func pausePlay()
  public func startPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool)
  public func startPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool, start: CoreMedia.CMTime, end: CoreMedia.CMTime)
}
@_hasMissingDesignatedInitializers public class VideoEditorServiceBuilder {
  public static func getNewEditorServicing(token: Swift.String, watermarkApplicator: VideoEditor.WatermarkApplicatorServicing) -> VideoEditor.VideoEditorService
  public static func getNewSequenceServicing() -> VideoEditor.VideoSequenceServicing
  public static func getPlayer(asset: AVFoundation.AVAsset, delegate: BanubaUtilities.PlayerDelegate?, instructions: [AVFoundation.AVVideoCompositionInstructionProtocol]?) -> BanubaUtilities.Playable
  @objc deinit
}
public protocol AppliedEffect : AnyObject {
  func getCurrentAppliedEffects(type: VideoEditor.EditorEffectType) -> [VideoEditor.EditorCompositionEffectProtocol]
  func startCurrentFilter(effectModel: VideoEditor.VideoEditorFilterModel, at: CoreMedia.CMTime)
  func endCurrentFilter(at: CoreMedia.CMTime)
  func undoLast(type: VideoEditor.EditorEffectType) -> VideoEditor.EditorCompositionEffectProtocol?
  func undoAll(type: VideoEditor.EditorEffectType)
  func getSpeed(at time: CoreMedia.CMTime) -> Swift.Float
  func applyFilter(effectModel: VideoEditor.VideoEditorFilterModel, start: CoreMedia.CMTime, end: CoreMedia.CMTime, removeSameType: Swift.Bool)
  func storeStack()
  func restoreStack()
  func hasChangesInAppliedEffects() -> Swift.Bool
}
@_hasMissingDesignatedInitializers public class EffectsSharedContext {
  public static var shared: VideoEditor.EffectsSharedContext
  public var context: OpenGLES.EAGLContext {
    get
  }
  final public let textureCache: VideoEditor.VideoTextureCache
  public func setCurrent()
  public func getProgram(vertexSource: Swift.String, fragmentSource: Swift.String) -> VideoEditor.GLProgram
  @objc deinit
}
public enum AssetRotation : Swift.UInt8, Swift.Codable {
  case none
  case rotate90
  case rotate180
  case rotate270
  public init?(withAngle angle: CoreGraphics.CGFloat)
  public var angle: CoreGraphics.CGFloat {
    get
  }
  public init?(rawValue: Swift.UInt8)
  public typealias RawValue = Swift.UInt8
  public var rawValue: Swift.UInt8 {
    get
  }
}
public enum EffectSpeed : Swift.Float {
  case normal
  case slowmo
  case rapid
  public init?(rawValue: Swift.Float)
  public typealias RawValue = Swift.Float
  public var rawValue: Swift.Float {
    get
  }
}
@_hasMissingDesignatedInitializers public class EditorCompositionFactory {
  @objc deinit
}
public protocol EditorCompositionEffectProtocol : AnyObject {
  var startTime: CoreMedia.CMTime { get }
  var endTime: CoreMedia.CMTime { get }
  var id: Swift.UInt { get }
  var tokenId: Swift.String { get set }
  var path: Swift.String { get }
}
public protocol Rotatable {
  var rotation: VideoEditor.AssetRotation { get set }
  func rotate(clockwise: Swift.Bool)
}
public class VideoEditorAssetTrackInfo {
  public var url: Foundation.URL {
    get
  }
  public var fillAspectRatioRange: Swift.ClosedRange<CoreGraphics.CGFloat>
  final public let videoResolutionConfiguration: BanubaUtilities.VideoResolutionConfiguration
  public var videoCurentSize: CoreGraphics.CGFloat?
  public var thumbnail: UIKit.UIImage?
  public var thumbnails: [UIKit.UIImage]
  public var trimTimeRange: CoreMedia.CMTimeRange
  public var rotation: VideoEditor.AssetRotation {
    get
    set(value)
  }
  public var videoName: Swift.String {
    get
  }
  public var isGalleryAsset: Swift.Bool
  public var composition: AVFoundation.AVComposition! {
    get
  }
  public var instructions: [AVFoundation.AVVideoCompositionInstructionProtocol]? {
    get
  }
  public var error: Swift.Error? {
    get
  }
  public var timeRange: CoreMedia.CMTimeRange {
    get
  }
  public var urlAsset: AVFoundation.AVAsset {
    get
  }
  public var timeRangeInGlobal: CoreMedia.CMTimeRange
  public init(url: Foundation.URL, rotation: VideoEditor.AssetRotation, thumbnail: UIKit.UIImage?, fillAspectRatioRange: Swift.ClosedRange<CoreGraphics.CGFloat>, videoResolutionConfiguration: BanubaUtilities.VideoResolutionConfiguration, isGalleryAsset: Swift.Bool)
  public func copy() -> VideoEditor.VideoEditorAssetTrackInfo
  public func replaceAssetUrl(_ url: Foundation.URL)
  public func rotate(clockwise: Swift.Bool)
  public func getTimeRangeWithSpeedExtension() -> CoreMedia.CMTimeRange
  @objc deinit
}
public struct MediaTrackTimeRange : Swift.Codable {
  public let startTime: CoreMedia.CMTime
  public let playingTimeRange: CoreMedia.CMTimeRange
  public init(startTime: CoreMedia.CMTime, playingTimeRange: CoreMedia.CMTimeRange)
  public init(from decoder: Swift.Decoder) throws
  public func encode(to encoder: Swift.Encoder) throws
}
public class MediaTrack : Swift.Codable {
  public static var unknownId: CoreMedia.CMPersistentTrackID
  public var id: CoreMedia.CMPersistentTrackID
  final public let url: Foundation.URL
  public var timeRange: VideoEditor.MediaTrackTimeRange
  final public let title: Swift.String?
  final public let isEditable: Swift.Bool
  public init(id: CoreMedia.CMPersistentTrackID, url: Foundation.URL, timeRange: VideoEditor.MediaTrackTimeRange, isEditable: Swift.Bool, title: Swift.String? = nil)
  @objc deinit
  public func encode(to encoder: Swift.Encoder) throws
  required public init(from decoder: Swift.Decoder) throws
}
public class GLProgram {
  public var initialized: Swift.Bool {
    get
  }
  public init(vertexSource: Swift.String, fragmentSource: Swift.String)
  @objc deinit
  public func add(attribute: Swift.String)
  public func getIndex(attribute: Swift.String) -> OpenGLES.GLuint
  public func getIndex(uniform: Swift.String) -> OpenGLES.GLint
  public func use()
  public func link() -> Swift.Bool
}
@objc public class ImageConfiguration : ObjectiveC.NSObject, BanubaUtilities.ImageConfigurationProtocol {
  public var imageName: Swift.String
  @objc public var image: UIKit.UIImage? {
    @objc get
  }
  public init(imageName: Swift.String)
  public init(image: UIKit.UIImage)
  @objc deinit
}
public struct WatermarkConfiguration {
  public var watermark: VideoEditor.ImageConfiguration
  public var size: CoreGraphics.CGSize
  public var sharedOffset: CoreGraphics.CGFloat
  public var position: VideoEditor.WatermarkConfiguration.WatermarkPosition
  public enum WatermarkPosition {
    case leftTop
    case leftBottom
    case rightTop
    case rightBottom
    public static func == (a: VideoEditor.WatermarkConfiguration.WatermarkPosition, b: VideoEditor.WatermarkConfiguration.WatermarkPosition) -> Swift.Bool
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
  }
  public init(watermark: VideoEditor.ImageConfiguration, size: CoreGraphics.CGSize, sharedOffset: CoreGraphics.CGFloat, position: VideoEditor.WatermarkConfiguration.WatermarkPosition)
}
public protocol VideoSequenceServicing {
  var videoSequences: [VideoEditor.VideoSequence] { get }
  var currentSequence: VideoEditor.VideoSequence? { get }
  func setupCurrentSequence(_ videoSequence: VideoEditor.VideoSequence?)
  @discardableResult
  func startNewSequence() -> VideoEditor.VideoSequence
  func cancelCurrentSequence()
  func duplicateSequence(_ videoSequence: VideoEditor.VideoSequence) -> VideoEditor.VideoSequence
  func replaceSequence(_ videoSequenceToReplace: VideoEditor.VideoSequence, withSequence videoSequence: VideoEditor.VideoSequence)
  func setModificationDate(_ date: Foundation.Date, forVideoSequence videoSequence: VideoEditor.VideoSequence)
  @discardableResult
  func removeSequence(_ videoSequence: VideoEditor.VideoSequence) -> Swift.Bool
  func removeAllSequences()
}
