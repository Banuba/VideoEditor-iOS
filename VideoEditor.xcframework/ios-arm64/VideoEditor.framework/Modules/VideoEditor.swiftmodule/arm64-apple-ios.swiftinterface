// swift-interface-format-version: 1.0
// swift-compiler-version: Apple Swift version 5.3.1 (swiftlang-1200.0.41 clang-1200.0.32.8)
// swift-module-flags: -target arm64-apple-ios11.0 -enable-objc-interop -enable-library-evolution -swift-version 5 -enforce-exclusivity=checked -O -module-name VideoEditor
import AVFoundation
import AVKit
import CoreGraphics
import CoreMedia
import CoreVideo
import Foundation
import GLKit
import OpenGLES
import Swift
import UIKit
@_exported import VideoEditor
public protocol VideoEditorImageAssetProtocol : AnyObject {
  var duration: Foundation.TimeInterval { get }
  var image: CoreGraphics.CGImage? { get }
  var shouldUseImageEffect: Swift.Bool { get }
  func getOrPreloadImage() -> CoreGraphics.CGImage?
  func unloadImage()
}
@_hasMissingDesignatedInitializers public class AudioMixer {
  public var audioMix: AVFoundation.AVAudioMix {
    get
  }
  public func resetVolumeToDefault(trackId: CoreMedia.CMPersistentTrackID)
  public func setVolume(volume: Swift.Float, for trackId: CoreMedia.CMPersistentTrackID)
  public func volume(for trackId: CoreMedia.CMPersistentTrackID) -> Swift.Float
  public func isVolumeDefault(for trackId: CoreMedia.CMPersistentTrackID) -> Swift.Bool
  @objc deinit
}
public protocol CompositionRenderering : AnyObject {
  init()
  func render(in pixelBuffer: CoreVideo.CVPixelBuffer, allSources: [CoreVideo.CVPixelBuffer], sampleTime: CoreMedia.CMTime, effect: VideoEditor.EditorCompositionEffectProtocol)
}
@_hasMissingDesignatedInitializers public class PlayersBundle {
  weak public var previewPlayerDelegate: VideoEditor.PreviewPlayerDelegate?
  public var isMuted: Swift.Bool {
    get
    set
  }
  @objc deinit
}
extension PlayersBundle : VideoEditor.Playable {
  public var currentTime: Foundation.TimeInterval {
    get
  }
  public var videoDuration: Swift.Double {
    get
  }
  public var currentTimeInCMTime: CoreMedia.CMTime {
    get
  }
  public var videoDurationCMTime: CoreMedia.CMTime {
    get
  }
  public var isPlaying: Swift.Bool {
    get
  }
  public var playerItem: AVFoundation.AVPlayerItem? {
    get
  }
  public var audioMix: AVFoundation.AVAudioMix? {
    get
    set
  }
  public var avPlayer: AVFoundation.AVPlayer {
    get
  }
  public func startPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool)
  public func startPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool, start: CoreMedia.CMTime, end: CoreMedia.CMTime)
  public func pausePlay()
  public func stopPlay()
  public func resumePlay()
  public func previewLayer() -> AVFoundation.AVPlayerLayer
  public func smoothlySeek(to time: CoreMedia.CMTime)
  public func seek(to time: CoreMedia.CMTime)
  public func startStopPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool)
  public func reloadPreview()
  public func reloadPreview(shouldAutoStart: Swift.Bool)
}
extension PlayersBundle : VideoEditor.PreviewPlayerDelegate {
  public func playerPlaysFrameAtTime(_ time: CoreMedia.CMTime)
  public func didEndPlaying()
}
public enum EditorEffectType {
  case color
  case visual
  case time
  case gif
  case text
  case mask
  public static func == (a: VideoEditor.EditorEffectType, b: VideoEditor.EditorEffectType) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
  public func hash(into hasher: inout Swift.Hasher)
}
public protocol VideoEditorTrackServicing {
  func hasAudioTrack() -> Swift.Bool
  func audioTrackVolume() -> Swift.Float
  func isAudioTrackVolumeChanged() -> Swift.Bool
  func setAudioTrackVolume(_ volume: Swift.Float)
  func setAudioTrackVolume(_ volume: Swift.Float, to player: VideoEditor.Playable?)
}
public protocol ImageSlideshow {
  func exportSlideshow(to: Foundation.URL, from images: [VideoEditor.VideoEditorImageAssetProtocol], quality: Swift.String, completion: ((Swift.Bool, Swift.Error?) -> Swift.Void)?)
}
public protocol VideoEditorServicing : VideoEditor.AppliedEffect, VideoEditor.ImageSlideshow, VideoEditor.VideoEditorTrackServicing {
  var asset: AVFoundation.AVAsset? { get }
  var exportFrameDuration: CoreMedia.CMTime { get set }
  func exportVideo(to fileURL: Foundation.URL, quality: Swift.String, watermarkFilterModel: VideoEditor.VideoEditorFilterModel?, completion: ((Swift.Bool, Swift.Error?) -> Swift.Void)?)
  func exportVideo(to fileURL: Foundation.URL, using exportVideoInfo: VideoEditor.ExportVideoInfo, watermarkFilterModel: VideoEditor.VideoEditorFilterModel?, completion: ((Swift.Bool, Swift.Error?) -> Swift.Void)?)
  func exportAudio(to fileURL: Foundation.URL, completion: ((Swift.Bool, Swift.Error?) -> Swift.Void)?)
  func getEditorEffects(type: VideoEditor.EditorEffectType) -> [VideoEditor.VideoEditorFilterModel]
  func setCurrentAsset(_ asset: VideoEditor.VideoEditorAsset)
  func getPlayer(delegate: VideoEditor.PreviewPlayerDelegate?) -> VideoEditor.Playable
  func setEditorEffects(_ effects: [VideoEditor.VideoEditorFilterModel], enableInternalEffects: Swift.Bool, internalEffectStartId: Swift.UInt)
  func getImageGenerator() -> AVFoundation.AVAssetImageGenerator?
  func videoPartsCount() -> Swift.Int
  static func getPlayer(asset: AVFoundation.AVAsset, delegate: VideoEditor.PreviewPlayerDelegate?) -> VideoEditor.Playable
  static func getPlayer(asset: AVFoundation.AVAsset, delegate: VideoEditor.PreviewPlayerDelegate?, instructions: [AVFoundation.AVVideoCompositionInstructionProtocol]?) -> VideoEditor.Playable
}
@_hasMissingDesignatedInitializers public class VideoEditorService {
  public var videoAsset: VideoEditor.VideoEditorAsset? {
    get
    set
  }
  public var asset: AVFoundation.AVAsset? {
    get
  }
  public var exportFrameDuration: CoreMedia.CMTime
  public var audioMixer: VideoEditor.AudioMixer?
  @objc deinit
}
extension VideoEditorService : VideoEditor.AppliedEffect {
  public func applyFilter(effectModel: VideoEditor.VideoEditorFilterModel, start: CoreMedia.CMTime, end: CoreMedia.CMTime, removeSameType: Swift.Bool)
  public func getSpeed(at time: CoreMedia.CMTime) -> Swift.Float
  public func undoLast(type: VideoEditor.EditorEffectType) -> VideoEditor.EditorCompositionEffectProtocol?
  public func undoAll(type: VideoEditor.EditorEffectType)
  public func startCurrentFilter(effectModel: VideoEditor.VideoEditorFilterModel, at: CoreMedia.CMTime)
  public func endCurrentFilter(at: CoreMedia.CMTime)
  public func getCurrentAppliedEffects(type: VideoEditor.EditorEffectType) -> [VideoEditor.EditorCompositionEffectProtocol]
  public func storeStack()
  public func restoreStack()
  public func hasChangesInAppliedEffects() -> Swift.Bool
}
extension VideoEditorService : VideoEditor.VideoEditorServicing {
  public static func getPlayer(asset: AVFoundation.AVAsset, delegate: VideoEditor.PreviewPlayerDelegate?) -> VideoEditor.Playable
  public static func getPlayer(asset: AVFoundation.AVAsset, delegate: VideoEditor.PreviewPlayerDelegate?, instructions: [AVFoundation.AVVideoCompositionInstructionProtocol]?) -> VideoEditor.Playable
  public func getImageGenerator() -> AVFoundation.AVAssetImageGenerator?
  public func exportVideo(to file: Foundation.URL, quality: Swift.String, watermarkFilterModel: VideoEditor.VideoEditorFilterModel?, completion: ((Swift.Bool, Swift.Error?) -> Swift.Void)?)
  public func exportVideo(to fileURL: Foundation.URL, using exportVideoInfo: VideoEditor.ExportVideoInfo, watermarkFilterModel: VideoEditor.VideoEditorFilterModel?, completion: ((Swift.Bool, Swift.Error?) -> Swift.Void)?)
  public func exportCleanVideo(to file: Foundation.URL, mediaInfo: VideoEditor.ExportVideoInfo, completion: ((Swift.Bool, Swift.Error?) -> Swift.Void)?)
  public func exportAudio(to fileURL: Foundation.URL, completion: ((Swift.Bool, Swift.Error?) -> Swift.Void)?)
  public func getEditorEffects(type: VideoEditor.EditorEffectType) -> [VideoEditor.VideoEditorFilterModel]
  public func setCurrentAsset(_ asset: VideoEditor.VideoEditorAsset)
  public func getPlayer(delegate: VideoEditor.PreviewPlayerDelegate?) -> VideoEditor.Playable
  public func setEditorEffects(_ effects: [VideoEditor.VideoEditorFilterModel], enableInternalEffects: Swift.Bool, internalEffectStartId: Swift.UInt)
  public func videoPartsCount() -> Swift.Int
}
extension VideoEditorService : VideoEditor.VideoEditorTrackServicing {
  public func audioTrackVolume() -> Swift.Float
  public func isAudioTrackVolumeChanged() -> Swift.Bool
  public func setAudioTrackVolume(_ volume: Swift.Float)
  public func setAudioTrackVolume(_ volume: Swift.Float, to player: VideoEditor.Playable?)
  public func hasAudioTrack() -> Swift.Bool
}
extension VideoEditorService : VideoEditor.ImageSlideshow {
  public func exportSlideshow(to url: Foundation.URL, from images: [VideoEditor.VideoEditorImageAssetProtocol], quality: Swift.String, completion: ((Swift.Bool, Swift.Error?) -> Swift.Void)?)
}
public class VideoTrimData {
  public var start: CoreMedia.CMTime {
    get
  }
  public var end: CoreMedia.CMTime {
    get
  }
  public var duration: CoreMedia.CMTime {
    get
  }
  public init(start: CoreMedia.CMTime, end: CoreMedia.CMTime)
  @objc deinit
}
@_hasMissingDesignatedInitializers public class MusicPlayer : VideoEditor.Playable {
  public var avPlayer: AVFoundation.AVPlayer {
    get
  }
  public var playerItem: AVFoundation.AVPlayerItem? {
    get
  }
  public var isMuted: Swift.Bool {
    get
    set
  }
  weak public var previewPlayerDelegate: VideoEditor.PreviewPlayerDelegate?
  public var isPlaying: Swift.Bool
  @objc deinit
}
extension MusicPlayer {
  public var videoDurationCMTime: CoreMedia.CMTime {
    get
  }
  public var videoDuration: Swift.Double {
    get
  }
  public var currentTimeInCMTime: CoreMedia.CMTime {
    get
  }
  public var currentTime: Foundation.TimeInterval {
    get
  }
  public var audioMix: AVFoundation.AVAudioMix? {
    get
    set
  }
  public func seek(to time: CoreMedia.CMTime)
  public func reloadPreview()
  public func reloadPreview(shouldAutoStart: Swift.Bool)
  public func startStopPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool)
  public func stopPlay()
  public func smoothlySeek(to time: CoreMedia.CMTime)
  public func previewLayer() -> AVFoundation.AVPlayerLayer
  public func resumePlay()
  public func pausePlay()
  public func startPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool)
  public func startPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool, start: CoreMedia.CMTime, end: CoreMedia.CMTime)
}
public protocol ExportScalable {
  func exportScaled(outputUrl: Foundation.URL, quality: Swift.String, trimData: VideoEditor.VideoTrimData?, completion: ((Swift.Error?) -> Swift.Void)?)
}
public class VideoEditorAsset {
  public var composition: AVFoundation.AVMutableComposition!
  final public let isSlideshow: Swift.Bool
  public var instructions: [AVFoundation.AVVideoCompositionInstructionProtocol]? {
    get
  }
  public var errors: [Swift.Error] {
    get
  }
  public var tracksInfo: [VideoEditor.VideoEditorAssetTrackInfo] {
    get
  }
  public init(tracks: [VideoEditor.VideoEditorAssetTrackInfo], musicTrack: VideoEditor.MediaTrack?, includeOriginalTrack: Swift.Bool = true, isDebugModeOn: Swift.Bool = false, fillAspectRatioRange: Swift.ClosedRange<CoreGraphics.CGFloat> = CGFloat(0)...CGFloat(0), isSlideshow: Swift.Bool, videoResolutionConfiguration: VideoEditor.VideoResolutionConfiguration)
  convenience public init(sequence: VideoEditor.VideoSequence, isDebugModeOn: Swift.Bool = false, fillAspectRatioRange: Swift.ClosedRange<CoreGraphics.CGFloat> = CGFloat(0)...CGFloat(0), videoResolutionConfiguration: VideoEditor.VideoResolutionConfiguration)
  public func reloadComposition()
  public func loadNonExistingThumbnails(completion: (() -> ())?)
  public func getPartIndex(at time: CoreMedia.CMTime) -> Swift.Int?
  @objc deinit
}
extension VideoEditorAsset {
  public func changeMusicTrackPosition(_ musicTrack: VideoEditor.MediaTrack) -> Swift.Bool
  public func addMusicTrack(_ musicTrack: VideoEditor.MediaTrack) -> (compositionTrack: AVFoundation.AVMutableCompositionTrack, assetTrack: AVFoundation.AVAssetTrack)?
  public func removeMusic(trackId: CoreMedia.CMPersistentTrackID) -> Swift.Bool
}
extension VideoEditorAsset : VideoEditor.ExportScalable {
  public func exportScaled(outputUrl: Foundation.URL, quality: Swift.String, trimData: VideoEditor.VideoTrimData?, completion: ((Swift.Error?) -> Swift.Void)?)
}
extension VideoEditorAsset {
  public func addTrackInfos(_ trackInfos: [VideoEditor.VideoEditorAssetTrackInfo])
  public func removeTrack(at index: Swift.Int)
  public func removeTrack(with info: VideoEditor.VideoEditorAssetTrackInfo)
  public func moveTrack(fromIndex: Swift.Int, toIndex: Swift.Int)
}
@_hasMissingDesignatedInitializers public class VideoEditorFilterModel {
  final public let filterType: VideoEditor.EditorEffectType
  final public let name: Swift.String
  final public let path: Swift.String
  public var id: Swift.UInt {
    get
  }
  convenience public init(name: Swift.String, type: VideoEditor.EditorEffectType, renderer: VideoEditor.CompositionRenderering.Type?, path: Swift.String = "", id: Swift.UInt, rendererInstance: VideoEditor.CompositionRenderering?)
  @objc deinit
}
public enum VideoResolution {
  case hd1280x720
  case hd1920x1080
  case default854x480
  public var ÑaptureSessionPreset: AVFoundation.AVCaptureSession.Preset {
    get
  }
  public var assetExportPreset: Swift.String {
    get
  }
  public var size: CoreGraphics.CGSize {
    get
  }
  public static func == (a: VideoEditor.VideoResolution, b: VideoEditor.VideoResolution) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
  public func hash(into hasher: inout Swift.Hasher)
}
public struct VideoResolutionConfiguration {
  public let `default`: VideoEditor.VideoResolution
  public let resolutions: [VideoEditor.DeviceModel : VideoEditor.VideoResolution]
  public let thumnailHeights: [VideoEditor.DeviceModel : CoreGraphics.CGFloat]
  public let defaultThumnailHeight: CoreGraphics.CGFloat
  public var current: VideoEditor.VideoResolution {
    get
  }
  public var currentThumnailHeight: CoreGraphics.CGFloat {
    get
  }
  public init(default: VideoEditor.VideoResolution, resolutions: [VideoEditor.DeviceModel : VideoEditor.VideoResolution], thumnailHeights: [VideoEditor.DeviceModel : CoreGraphics.CGFloat], defaultThumnailHeight: CoreGraphics.CGFloat)
}
public enum DeviceModel : Swift.String {
  case simulator, iPod1, iPod2, iPod3, iPod4, iPod5, iPad2, iPad3, iPad4, iPhone4, iPhone4S, iPhone5, iPhone5S, iPhone5C, iPadMini1, iPadMini2, iPadMini3, iPadAir1, iPadAir2, iPadPro9_7, iPadPro9_7_cell, iPadPro10_5, iPadPro10_5_cell, iPadPro12_9, iPadPro12_9_cell, iPhone6, iPhone6plus, iPhone6S, iPhone6Splus, iPhoneSE, iPhone7, iPhone7plus, iPhone8, iPhone8plus, iPhoneX, iPhoneXS, iPhoneXSmax, iPhoneXR, iPhone11, iPhone11Pro, iPhone11ProMax, unrecognized
  public typealias RawValue = Swift.String
  public init?(rawValue: Swift.String)
  public var rawValue: Swift.String {
    get
  }
}
extension UIDevice {
  public var type: VideoEditor.DeviceModel {
    get
  }
}
public class VideoSequenceItem {
  final public let originalURL: Foundation.URL
  final public let path: Swift.String
  final public let duration: Foundation.TimeInterval
  final public let preview: UIKit.UIImage?
  public var additionalInfo: Any?
  public init(assetUrl url: Foundation.URL, originalURL: Foundation.URL, preview: UIKit.UIImage?)
  @objc deinit
}
@_hasMissingDesignatedInitializers public class VideoSequence {
  public var videos: [VideoEditor.VideoSequenceItem]
  public var durations: [Foundation.TimeInterval] {
    get
  }
  public var musicTrack: VideoEditor.MediaTrack? {
    get
  }
  final public let isSlideshow: Swift.Bool
  final public let includeOriginalTrack: Swift.Bool
  public func totalDuration() -> Foundation.TimeInterval
  public static func restore(folder: Foundation.URL) -> VideoEditor.VideoSequence
  @objc deinit
}
@objc public class VoiceTrackItem : ObjectiveC.NSObject {
  final public let url: Foundation.URL
  final public let timeRange: CoreMedia.CMTimeRange
  public init(url: Foundation.URL, timeRange: CoreMedia.CMTimeRange)
  @objc deinit
  @objc override dynamic public init()
}
public class ExportVideoInfo {
  final public let width: Swift.Int
  final public let height: Swift.Int
  final public let bitrate: Swift.Int
  final public let frameRate: Swift.Int
  final public let codecType: AVFoundation.AVVideoCodecType
  final public let scalingMode: Swift.String
  public init(width: Swift.Int, height: Swift.Int, bitrate: Swift.Int, frameRate: Swift.Int, codecType: AVFoundation.AVVideoCodecType, scalingMode: Swift.String)
  @objc deinit
}
public protocol Playable : AnyObject {
  func startPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool)
  func startPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool, start: CoreMedia.CMTime, end: CoreMedia.CMTime)
  func pausePlay()
  func stopPlay()
  func resumePlay()
  func previewLayer() -> AVFoundation.AVPlayerLayer
  func smoothlySeek(to time: CoreMedia.CMTime)
  func seek(to time: CoreMedia.CMTime)
  func startStopPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool)
  func reloadPreview()
  func reloadPreview(shouldAutoStart: Swift.Bool)
  var currentTime: Foundation.TimeInterval { get }
  var videoDuration: Swift.Double { get }
  var currentTimeInCMTime: CoreMedia.CMTime { get }
  var videoDurationCMTime: CoreMedia.CMTime { get }
  var isPlaying: Swift.Bool { get }
  var playerItem: AVFoundation.AVPlayerItem? { get }
  var audioMix: AVFoundation.AVAudioMix? { get set }
  var previewPlayerDelegate: VideoEditor.PreviewPlayerDelegate? { get set }
  var avPlayer: AVFoundation.AVPlayer { get }
  var isMuted: Swift.Bool { get set }
}
@_hasMissingDesignatedInitializers public class EditorPlayer {
  public var avPlayer: AVFoundation.AVPlayer {
    get
  }
  public var playerItem: AVFoundation.AVPlayerItem? {
    get
  }
  public var isMuted: Swift.Bool {
    get
    set
  }
  weak public var previewPlayerDelegate: VideoEditor.PreviewPlayerDelegate?
  public var isPlaying: Swift.Bool
  @objc deinit
}
extension EditorPlayer : VideoEditor.Playable {
  public var videoDurationCMTime: CoreMedia.CMTime {
    get
  }
  public var videoDuration: Swift.Double {
    get
  }
  public var currentTimeInCMTime: CoreMedia.CMTime {
    get
  }
  public var currentTime: Foundation.TimeInterval {
    get
  }
  public var audioMix: AVFoundation.AVAudioMix? {
    get
    set
  }
  public func seek(to time: CoreMedia.CMTime)
  public func reloadPreview()
  public func reloadPreview(shouldAutoStart: Swift.Bool)
  public func startStopPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool)
  public func stopPlay()
  public func smoothlySeek(to time: CoreMedia.CMTime)
  public func previewLayer() -> AVFoundation.AVPlayerLayer
  public func resumePlay()
  public func pausePlay()
  public func startPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool)
  public func startPlay(loop: Swift.Bool, fixedSpeed: Swift.Bool, start: CoreMedia.CMTime, end: CoreMedia.CMTime)
}
public protocol AppliedEffect : AnyObject {
  func getCurrentAppliedEffects(type: VideoEditor.EditorEffectType) -> [VideoEditor.EditorCompositionEffectProtocol]
  func startCurrentFilter(effectModel: VideoEditor.VideoEditorFilterModel, at: CoreMedia.CMTime)
  func endCurrentFilter(at: CoreMedia.CMTime)
  func undoLast(type: VideoEditor.EditorEffectType) -> VideoEditor.EditorCompositionEffectProtocol?
  func undoAll(type: VideoEditor.EditorEffectType)
  func getSpeed(at time: CoreMedia.CMTime) -> Swift.Float
  func applyFilter(effectModel: VideoEditor.VideoEditorFilterModel, start: CoreMedia.CMTime, end: CoreMedia.CMTime, removeSameType: Swift.Bool)
  func storeStack()
  func restoreStack()
  func hasChangesInAppliedEffects() -> Swift.Bool
}
public protocol EditorCompositionEffectProtocol : AnyObject {
  var startTime: CoreMedia.CMTime { get }
  var endTime: CoreMedia.CMTime { get }
  var id: Swift.UInt { get }
  var path: Swift.String { get }
}
@_hasMissingDesignatedInitializers public class VideoEditorServiceBuilder {
  public static func getNewEditorServicing() -> VideoEditor.VideoEditorService
  public static func getNewSequenceServicing() -> VideoEditor.VideoSequenceServicing
  public static func getPlayer(asset: AVFoundation.AVAsset, delegate: VideoEditor.PreviewPlayerDelegate?, instructions: [AVFoundation.AVVideoCompositionInstructionProtocol]?) -> VideoEditor.Playable
  @objc deinit
}
public protocol PreviewPlayerDelegate : AnyObject {
  func playerPlaysFrameAtTime(_ time: CoreMedia.CMTime)
  func didEndPlaying()
}
public class VideoEditorAssetTrackInfo {
  public var originalURL: Foundation.URL {
    get
  }
  public var composition: AVFoundation.AVComposition! {
    get
  }
  public var thumbnail: UIKit.UIImage? {
    get
  }
  public var timeRange: CoreMedia.CMTimeRange {
    get
  }
  public var trimTimeRange: CoreMedia.CMTimeRange
  public var instructions: [AVFoundation.AVVideoCompositionInstructionProtocol]? {
    get
  }
  public var thumbnails: [UIKit.UIImage]
  public var error: Swift.Error? {
    get
  }
  public init(url: Foundation.URL, originalURL: Foundation.URL, thumbnail: UIKit.UIImage?, fillAspectRatioRange: Swift.ClosedRange<CoreGraphics.CGFloat>, videoResolutionConfiguration: VideoEditor.VideoResolutionConfiguration)
  @objc deinit
}
public struct MediaTrackTimeRange {
  public let startTime: CoreMedia.CMTime
  public let playingTimeRange: CoreMedia.CMTimeRange
  public init(startTime: CoreMedia.CMTime, playingTimeRange: CoreMedia.CMTimeRange)
}
public class MediaTrack {
  public static let unknownId: CoreMedia.CMPersistentTrackID
  final public let id: CoreMedia.CMPersistentTrackID
  final public let url: Foundation.URL
  final public let timeRange: VideoEditor.MediaTrackTimeRange
  final public let title: Swift.String?
  public init(id: CoreMedia.CMPersistentTrackID, url: Foundation.URL, timeRange: VideoEditor.MediaTrackTimeRange, title: Swift.String? = nil)
  @objc deinit
}
public protocol VideoSequenceServicing {
  var videoSequences: [VideoEditor.VideoSequence] { get }
  var currentSequence: VideoEditor.VideoSequence? { get }
  func startNewSequence(musicTrack: VideoEditor.MediaTrack?, isSlideshow: Swift.Bool, includeOriginalTrack: Swift.Bool)
  func startNewSequenceIfNeeded(musicTrack: VideoEditor.MediaTrack?, includeOriginalTrack: Swift.Bool)
  func cancelCurrentSequence()
  func removeAllSequences()
  func resetSequences()
  func addVideo(at url: Foundation.URL, speed: Swift.Double, preview: UIKit.UIImage?)
  func removeLastVideo() -> VideoEditor.VideoSequenceItem?
}
extension VideoEditor.EditorEffectType : Swift.Equatable {}
extension VideoEditor.EditorEffectType : Swift.Hashable {}
extension VideoEditor.VideoResolution : Swift.Equatable {}
extension VideoEditor.VideoResolution : Swift.Hashable {}
extension VideoEditor.DeviceModel : Swift.Equatable {}
extension VideoEditor.DeviceModel : Swift.Hashable {}
extension VideoEditor.DeviceModel : Swift.RawRepresentable {}
